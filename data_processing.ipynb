{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  模块与数据导入\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import missingno as msno\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import featuretools as ft\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,Normalizer,PolynomialFeatures\n",
    "\n",
    "Train_data = pd.read_csv(\"Dataset/train/outputs/主蒸汽流量.csv\")\n",
    "\n",
    "for path, dirs, files in os.walk(\"Dataset/train/inputs\"):\n",
    "    for file in files:\n",
    "        temp = pd.read_csv(os.path.join(path, file))\n",
    "        temp.drop_duplicates('时间', inplace=True)\n",
    "        Train_data = Train_data.merge(temp, on=['时间'], how='left')\n",
    "\n",
    "Test_data = pd.read_csv(\"Dataset/test/二次风调门.csv\")['时间'].to_frame()\n",
    "for path, dirs, files in os.walk(\"Dataset/test\"):\n",
    "    for file in files:\n",
    "        temp = pd.read_csv(os.path.join(path, file))\n",
    "        temp.drop_duplicates('时间', inplace=True)\n",
    "        Test_data = Test_data.merge(temp, on=['时间'], how='left')\n",
    "\n",
    "Train_data['Is_Test'] = 0\n",
    "Test_data['Is_Test'] = 1\n",
    "\n",
    "combi = pd.concat([Train_data, Test_data], axis=0, ignore_index=True)\n",
    "\n",
    "combi.rename(columns={'时间':'Time', '主蒸汽流量':'Steam_flow', '二次风调门':'2_air_door', '炉排启停':'Grate_switch', '二次风量':'2wind',\\\n",
    "     '一次风量':'1wind', '一次风调门':'1_air_door', '氧量设定值':'O2', '推料器自动投退信号':'Push_auto_feed', 'SO2含量':'SO2',\n",
    "      '推料器手动指令':'Manual_feed', 'CO含量':'CO', '主蒸汽流量设定值':'Steam_flow_set', '汽包水位':'Water_level', '推料器自动指令':'Push_auto',\n",
    "       'HCL含量':'HCL','NOx含量':'NOx', '炉排实际运行指令':'Grate_run', '炉排手动指令':'Grate_manual', '给水流量':'Water_flow',\n",
    "       '炉排自动投退信号':'Grate_auto', '推料器启停':'Feed_switch', '引风机转速':'Fan_speed'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间信息拆解\n",
    "combi['days'] = pd.to_datetime(combi['Time'],format='%Y-%m-%d %H:%M:%S').dt.day\n",
    "combi['hours'] = pd.to_datetime(combi['Time'],format='%Y-%m-%d %H:%M:%S').dt.hour\n",
    "combi['minutes'] = pd.to_datetime(combi['Time'],format='%Y-%m-%d %H:%M:%S').dt.minute\n",
    "combi['seconds'] = pd.to_datetime(combi['Time'],format='%Y-%m-%d %H:%M:%S').dt.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 通用函数定义\n",
    "\n",
    "def feat_kernelMedian(df, df_feature, fe, value, pr, name=\"\"):\n",
    "    def get_median(a, pr=pr):\n",
    "        a = np.array(a)\n",
    "        x = a[~np.isnan(a)]\n",
    "        n = len(x)\n",
    "        weight = np.repeat(1.0, n)\n",
    "        idx = np.argsort(x)\n",
    "        x = x[idx]\n",
    "        if n<pr.shape[0]:\n",
    "            pr = pr[n,:n]\n",
    "        else:\n",
    "            scale = (n-1)/2.\n",
    "            xxx = np.arange(-(n+1)/2.+1, (n+1)/2., step=1)/scale\n",
    "            yyy = 3./4.*(1-xxx**2)\n",
    "            yyy = yyy/np.sum(yyy)\n",
    "            pr = (yyy*n+1)/(n+1)\n",
    "        ans = np.sum(pr*x*weight) / float(np.sum(pr * weight))\n",
    "        return ans\n",
    "\n",
    "    df_count = pd.DataFrame(df_feature.groupby(fe)[value].apply(get_median)).reset_index()\n",
    "    if not name:\n",
    "        df_count.columns = fe + [value+\"_%s_mean\" % (\"_\".join(fe))]\n",
    "    else:\n",
    "        df_count.columns = fe + [name]\n",
    "    df = df.merge(df_count, on=fe, how=\"left\").fillna(0)\n",
    "    return df\n",
    "    \n",
    "def merge_mean(df,columns,value,cname):\n",
    "    add = pd.DataFrame(df.groupby(columns)[value].mean()).reset_index()\n",
    "    add.columns=columns+[cname]\n",
    "    df=df.merge(add,on=columns,how=\"left\")\n",
    "    return df\n",
    "\n",
    "def outliers_proc(data, col_name, scale=3):\n",
    "    \"\"\"\n",
    "    用于清洗异常值，默认用 box_plot（scale=3）进行清洗\n",
    "    :param data: 接收 pandas 数据格式\n",
    "    :param col_name: pandas 列名\n",
    "    :param scale: 尺度\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    def box_plot_outliers(data_ser, box_scale):\n",
    "        \"\"\"\n",
    "        利用箱线图去除异常值\n",
    "        :param data_ser: 接收 pandas.Series 数据格式\n",
    "        :param box_scale: 箱线图尺度，\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        iqr = box_scale * (data_ser.quantile(0.75) - data_ser.quantile(0.25))\n",
    "        val_low = data_ser.quantile(0.25) - iqr\n",
    "        val_up = data_ser.quantile(0.75) + iqr\n",
    "        rule_low = (data_ser < val_low)\n",
    "        rule_up = (data_ser > val_up)\n",
    "        return (rule_low, rule_up), (val_low, val_up)\n",
    "\n",
    "    data_n = data.copy()\n",
    "    data_series = data_n[col_name]\n",
    "    rule, value = box_plot_outliers(data_series, box_scale=scale)\n",
    "    index = np.arange(data_series.shape[0])[rule[0] | rule[1]]\n",
    "    print(\"Delete number is: {}\".format(len(index)))\n",
    "    data_n = data_n.drop(index)\n",
    "    data_n.reset_index(drop=True, inplace=True)\n",
    "    print(\"Now column number is: {}\".format(data_n.shape[0]))\n",
    "    index_low = np.arange(data_series.shape[0])[rule[0]]\n",
    "    outliers = data_series.iloc[index_low]\n",
    "    print(\"Description of data less than the lower bound is:\")\n",
    "    print(pd.Series(outliers).describe())\n",
    "    index_up = np.arange(data_series.shape[0])[rule[1]]\n",
    "    outliers = data_series.iloc[index_up]\n",
    "    print(\"Description of data larger than the upper bound is:\")\n",
    "    print(pd.Series(outliers).describe())\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 7))\n",
    "    sns.boxplot(y=data[col_name], data=data, palette=\"Set1\", ax=ax[0])\n",
    "    sns.boxplot(y=data_n[col_name], data=data_n, palette=\"Set1\", ax=ax[1])\n",
    "    return data_n\n",
    "\n",
    "# Feiyang: 1. 获得核函数 PrEp\n",
    "PrOriginalEp = np.zeros((2000,2000))\n",
    "PrOriginalEp[1,0] = 1\n",
    "PrOriginalEp[2,range(2)] = [0.5,0.5]\n",
    "for i in range(3,2000):\n",
    "    scale = (i-1)/2.\n",
    "    x = np.arange(-(i+1)/2.+1, (i+1)/2., step=1)/scale\n",
    "    y = 3./4.*(1-x**2)\n",
    "    y = y/np.sum(y)\n",
    "    PrOriginalEp[i, range(i)] = y\n",
    "PrEp = PrOriginalEp.copy()\n",
    "for i in range(3, 2000):\n",
    "    PrEp[i,:i] = (PrEp[i,:i]*i+1)/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 参数设置\n",
    "Missing_value_proc = 2\n",
    "outliers_proc = False\n",
    "poly_features = False\n",
    "linear_features = False\n",
    "scaler_proc = False\n",
    "boxcox_proc = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 异常值处理 # TODO\n",
    "if outliers_proc:\n",
    "    combi = outliers_proc(combi, 'Radiation', scale=3)\n",
    "    combi = outliers_proc(combi, 'Temp', scale=3)\n",
    "    combi = outliers_proc(combi, 'Spd', scale=3)\n",
    "    combi = outliers_proc(combi, 'Dir', scale=3)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 缺失值处理\n",
    "# 对lightgbm和xgboost来说，缺失值处理不是必须的，但是对于其他模型来说，缺失值处理是必须的\n",
    "# 选择1，用前一个值填充\n",
    "# 选择2，丢弃缺失值\n",
    "# 选择3，模型预测填充\n",
    "# 选择4, 不处理\n",
    "if Missing_value_proc == 1:\n",
    "    combi['Temp'] = combi['Temp'].fillna(method='ffill')\n",
    "    combi['Spd'] = combi['Spd'].fillna(method='ffill')\n",
    "    combi['Dir'] = combi['Dir'].fillna(method='ffill')\n",
    "elif Missing_value_proc == 2:\n",
    "    combi.dropna(axis=0,how='any',subset=['Grate_switch'], inplace=True)\n",
    "elif Missing_value_proc == 3:\n",
    "    pass\n",
    "elif Missing_value_proc == 4:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 生成一些新的信息\n",
    "combi['Water_flow_shift'] = combi['Water_flow'].shift(-276)\n",
    "combi['Water_flow_mean']  = combi['Water_flow_shift'].rolling(window=552, min_periods=1, center=True).mean()\n",
    "combi['Water_level_diff'] = combi['Water_level'].diff(20)\n",
    "\n",
    "Water_level_cum = (np.cumsum(combi['Water_level']-combi['Water_level'].mean())/200).shift(-61)\n",
    "combi['Water_level_cum'] = Water_level_cum + combi['Water_flow']\n",
    "combi['Water_level_cum'][-61:] = combi['Water_level_cum'][258992:259053]+14.3352\n",
    "combi['Water_level_cum_rolling'] = combi['Water_level_cum'].rolling(3000, center=True, min_periods=1).mean()\n",
    "combi['Steam_flow_rolling'] = combi['Steam_flow'].rolling(3000, center=True, min_periods=1).mean()\n",
    "combi['simu'] = combi['Water_level_cum'] - combi['Water_level_cum_rolling'] + combi['Steam_flow_rolling']\n",
    "combi['simu'][-1800:] = combi['Water_level_cum'][-1800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 特征组合\n",
    "\n",
    "# 多项式特征\n",
    "if poly_features:\n",
    "    combi_poly = combi[['Temp', 'Spd', 'Temp_day_mean', 'Temp_day_median', 'Temp_hour_mean', 'Temp_hour_median', \\\n",
    "                        'Ratio_Hour_median', 'Radiation_hour_mean', 'Radiation_hour_median']]\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "    combi_poly = poly.fit_transform(combi_poly)\n",
    "    combi_poly = pd.DataFrame(combi_poly, columns=poly.get_feature_names_out())\n",
    "\n",
    "# 线性特征\n",
    "elif linear_features:\n",
    "    es = ft.EntitySet(id=\"radia\")\n",
    "    es.add_dataframe(dataframe_name=\"Elec3\", dataframe=combi, index=\"index\")\n",
    "    \n",
    "    trans_primitives=['add_numeric', 'subtract_numeric', 'multiply_numeric', 'divide_numeric']\n",
    "    agg_primitives=['sum', 'median','mean']\n",
    "    combi_linear, feature_names = ft.dfs(entityset=es, \n",
    "                                           target_dataframe_name = 'Elec3', \n",
    "                                           max_depth = 1, \n",
    "                                           verbose = 1,\n",
    "                                           agg_primitives=agg_primitives,\n",
    "                                           trans_primitives=trans_primitives,\n",
    "                                           n_jobs = 8)\n",
    "    \n",
    "    combi_linear = combi_linear.reindex(index=combi[\"index\"])\n",
    "    combi_linear = combi_linear.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据归一化与标准化\n",
    "features = combi.select_dtypes(include=['int64', 'float64']).drop('Steam_flow', axis=1).columns\n",
    "if scaler_proc == True:\n",
    "    scaler = [PolynomialFeatures(len(features)), MinMaxScaler(), StandardScaler(), Normalizer()]\n",
    "    x_train=scaler[1].fit_transform(combi[features])\n",
    "\n",
    "    for i in np.arange(len(features)):\n",
    "        combi[features[i]] = x_train[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxcox\n",
    "features = combi.select_dtypes(include=['int64', 'float64']).drop('Steam_flow', axis=1).columns\n",
    "if boxcox_proc == True:\n",
    "    for i in np.arange(len(features)):\n",
    "        combi[features[i]] = scipy.special.boxcox1p(combi[features[i]], 0)\n",
    "        # combi_copy[features[i]], _ = stats.boxcox(combi[features[i]]+0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for deep learning\n",
    "# dcd = pd.read_csv(\"Dataset/decomposed_data.csv\")\n",
    "# combi['date'] = dcd['ds']\n",
    "# combi = combi[combi['Day'] < 300]\n",
    "# combi = combi[['date','Temp', 'Spd', 'Temp_day_median', 'Spd_day_median', 'Diff_Temp_Day', 'Radiation_hour_median',\\\n",
    "#             'Diff_Temp_Hour','Temp_day_max_min', 'Temp_day_max_median', 'Temp_day_relative', 'Radiation']]\n",
    "# combi.to_csv(\"/mnt/DATA1/wuliubin/Download/Elec3/LTSF-Linear/dataset/elec3.csv\", index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi.to_csv(\"Dataset/combi.csv\", index=False, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('metro')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7382409c0718be7deb72b4417a98bad7c6c9b79245512f2c3556c6c05fa6b9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
